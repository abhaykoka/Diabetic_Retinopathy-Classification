{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11336197,"sourceType":"datasetVersion","datasetId":7091374}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport shutil\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Flatten, Dense, BatchNormalization, LeakyReLU, Dropout\nfrom sklearn.model_selection import KFold\nimport pandas as pd\nfrom IPython.display import FileLink\n\n# âœ… Configuration\nMODEL_NAME = \"CustomVGG16\"\nIMG_SIZE = (128, 128)\nBATCH_SIZE = 32\nEPOCHS = 75  # You can set to 100 for longer training\nNUM_FOLDS = 5\nSEED = 42\nIMG_DIR = \"/kaggle/input/augmented-dr-dataset/Augmented_DR_Dataset\"\nMODEL_SAVE_DIR = f\"/kaggle/working/{MODEL_NAME}\"\nRESULTS_CSV_PATH = f\"{MODEL_SAVE_DIR}/training_results.csv\"\nos.makedirs(MODEL_SAVE_DIR, exist_ok=True)\n\n# âœ… Load Dataset\nimage_files = []\nfor root, _, files in os.walk(IMG_DIR):\n    for file in files:\n        if file.endswith('.png'):\n            image_files.append(os.path.join(root, file))\n\nprint(f\"Found {len(image_files)} image files.\")\n\n# âœ… Extract labels from subfolder names\nlabels = [os.path.basename(os.path.dirname(f)) for f in image_files]\n\n# âœ… Create DataFrame\ndata_df = pd.DataFrame({\"filename\": image_files, \"label\": labels})\nprint(f\"Total Images Found: {len(data_df)}\")\nclass_names = sorted(data_df[\"label\"].unique())\n\n# âœ… Define Custom VGG16-based Model\ndef build_custom_vgg16(input_shape=(128, 128, 3), num_classes=5):\n    base_model = VGG16(include_top=False, weights=None, input_shape=input_shape)\n\n    model = Sequential([\n        base_model,\n        Flatten(),\n        Dense(128),\n        BatchNormalization(),\n        LeakyReLU(alpha=0.01),\n        Dropout(0.5),\n\n        Dense(64),\n        BatchNormalization(),\n        LeakyReLU(alpha=0.01),\n        Dropout(0.5),\n\n        Dense(num_classes, activation='softmax')\n    ])\n\n    model.compile(\n        optimizer=Adam(learning_rate=0.001),\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    return model\n\n# âœ… K-Fold Cross Validation\nkf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=SEED)\nresults = []\n\n# âœ… Training Loop\nfor fold, (train_idx, val_idx) in enumerate(kf.split(data_df)):\n    print(f\"\\n========= ğŸ† Fold {fold+1}/{NUM_FOLDS} =========\")\n\n    train_df, val_df = data_df.iloc[train_idx], data_df.iloc[val_idx]\n\n    # âœ… Data Augmentation\n    train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=20, horizontal_flip=True)\n    val_datagen = ImageDataGenerator(rescale=1./255)\n\n    train_gen = train_datagen.flow_from_dataframe(train_df, x_col=\"filename\", y_col=\"label\", \n                                                  target_size=IMG_SIZE, batch_size=BATCH_SIZE, \n                                                  class_mode=\"categorical\")\n    val_gen = val_datagen.flow_from_dataframe(val_df, x_col=\"filename\", y_col=\"label\", \n                                              target_size=IMG_SIZE, batch_size=BATCH_SIZE, \n                                              class_mode=\"categorical\")\n\n    # âœ… Build Model\n    model = build_custom_vgg16(input_shape=(*IMG_SIZE, 3), num_classes=len(class_names))\n\n    # âœ… Checkpointing\n    fold_model_name = f\"{MODEL_NAME}_fold_{fold+1}.keras\"\n    checkpoint_path = os.path.join(MODEL_SAVE_DIR, fold_model_name)\n    checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, save_best_only=True, monitor='val_accuracy', mode='max')\n\n    # âœ… Train Model\n    history = model.fit(train_gen, validation_data=val_gen, epochs=EPOCHS, callbacks=[checkpoint])\n\n    # âœ… Best Results\n    best_val_acc = max(history.history['val_accuracy'])\n    best_val_loss = min(history.history['val_loss'])\n\n    results.append({\n        \"Model\": MODEL_NAME,\n        \"Fold\": fold + 1,\n        \"Best Val Accuracy\": best_val_acc,\n        \"Best Val Loss\": best_val_loss\n    })\n\n# âœ… Save Results CSV\nresults_df = pd.DataFrame(results)\nresults_df.to_csv(RESULTS_CSV_PATH, index=False)\nprint(f\"\\nğŸ“Š Training results saved to: {RESULTS_CSV_PATH}\")\nprint(f\"ğŸ¯ Best models saved at: {MODEL_SAVE_DIR}\")\n\n# âœ… Zip and Provide Download Link\nshutil.make_archive(MODEL_SAVE_DIR, 'zip', MODEL_SAVE_DIR)\ndisplay(FileLink(f\"{MODEL_SAVE_DIR}.zip\"))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-09T16:51:44.614295Z","iopub.execute_input":"2025-04-09T16:51:44.614530Z","iopub.status.idle":"2025-04-09T19:10:19.559510Z","shell.execute_reply.started":"2025-04-09T16:51:44.614507Z","shell.execute_reply":"2025-04-09T19:10:19.558703Z"}},"outputs":[{"name":"stdout","text":"Found 3493 image files.\nTotal Images Found: 3493\n\n========= ğŸ† Fold 1/5 =========\nFound 2794 validated image filenames belonging to 5 classes.\nFound 699 validated image filenames belonging to 5 classes.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/75\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 585ms/step - accuracy: 0.2760 - loss: 1.9636 - val_accuracy: 0.4664 - val_loss: 1.2686\nEpoch 2/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 218ms/step - accuracy: 0.5942 - loss: 1.0658 - val_accuracy: 0.6853 - val_loss: 0.8579\nEpoch 3/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 204ms/step - accuracy: 0.6721 - loss: 0.9715 - val_accuracy: 0.6481 - val_loss: 1.0123\nEpoch 4/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 213ms/step - accuracy: 0.6869 - loss: 0.8726 - val_accuracy: 0.6767 - val_loss: 1.6276\nEpoch 5/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 207ms/step - accuracy: 0.7234 - loss: 0.8175 - val_accuracy: 0.6767 - val_loss: 0.8530\nEpoch 6/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 211ms/step - accuracy: 0.7273 - loss: 0.7887 - val_accuracy: 0.5494 - val_loss: 1.0234\nEpoch 7/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 222ms/step - accuracy: 0.7376 - loss: 0.7766 - val_accuracy: 0.7110 - val_loss: 0.8202\nEpoch 8/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 220ms/step - accuracy: 0.7589 - loss: 0.7425 - val_accuracy: 0.7282 - val_loss: 0.7164\nEpoch 9/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 207ms/step - accuracy: 0.7390 - loss: 0.7738 - val_accuracy: 0.7253 - val_loss: 0.7058\nEpoch 10/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 211ms/step - accuracy: 0.7717 - loss: 0.7084 - val_accuracy: 0.7225 - val_loss: 0.7207\nEpoch 11/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 215ms/step - accuracy: 0.7651 - loss: 0.7148 - val_accuracy: 0.7296 - val_loss: 0.7441\nEpoch 12/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 211ms/step - accuracy: 0.7627 - loss: 0.7183 - val_accuracy: 0.6924 - val_loss: 0.8556\nEpoch 13/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 204ms/step - accuracy: 0.7558 - loss: 0.7259 - val_accuracy: 0.7196 - val_loss: 0.7254\nEpoch 14/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 205ms/step - accuracy: 0.7639 - loss: 0.6905 - val_accuracy: 0.7253 - val_loss: 0.7489\nEpoch 15/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 220ms/step - accuracy: 0.7603 - loss: 0.6856 - val_accuracy: 0.7310 - val_loss: 0.7041\nEpoch 16/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 214ms/step - accuracy: 0.7701 - loss: 0.6775 - val_accuracy: 0.7239 - val_loss: 0.8492\nEpoch 17/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 207ms/step - accuracy: 0.7619 - loss: 0.6935 - val_accuracy: 0.7153 - val_loss: 0.7567\nEpoch 18/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 206ms/step - accuracy: 0.7595 - loss: 0.7036 - val_accuracy: 0.7024 - val_loss: 0.7912\nEpoch 19/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 209ms/step - accuracy: 0.7617 - loss: 0.6912 - val_accuracy: 0.7239 - val_loss: 0.7246\nEpoch 20/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 225ms/step - accuracy: 0.7632 - loss: 0.6827 - val_accuracy: 0.7339 - val_loss: 0.7048\nEpoch 21/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 207ms/step - accuracy: 0.7674 - loss: 0.7094 - val_accuracy: 0.7096 - val_loss: 0.8024\nEpoch 22/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 214ms/step - accuracy: 0.7690 - loss: 0.6673 - val_accuracy: 0.7282 - val_loss: 0.6986\nEpoch 23/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 214ms/step - accuracy: 0.7612 - loss: 0.7096 - val_accuracy: 0.7310 - val_loss: 0.6991\nEpoch 24/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 205ms/step - accuracy: 0.7451 - loss: 0.7012 - val_accuracy: 0.7268 - val_loss: 0.7074\nEpoch 25/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 206ms/step - accuracy: 0.7655 - loss: 0.6445 - val_accuracy: 0.7310 - val_loss: 0.6898\nEpoch 26/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 210ms/step - accuracy: 0.7628 - loss: 0.6636 - val_accuracy: 0.7339 - val_loss: 0.7026\nEpoch 27/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 206ms/step - accuracy: 0.7628 - loss: 0.6713 - val_accuracy: 0.7024 - val_loss: 0.8274\nEpoch 28/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 208ms/step - accuracy: 0.7707 - loss: 0.6770 - val_accuracy: 0.7253 - val_loss: 0.6883\nEpoch 29/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 207ms/step - accuracy: 0.7649 - loss: 0.6558 - val_accuracy: 0.7167 - val_loss: 0.6949\nEpoch 30/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 205ms/step - accuracy: 0.7555 - loss: 0.7064 - val_accuracy: 0.7282 - val_loss: 0.7119\nEpoch 31/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 206ms/step - accuracy: 0.7713 - loss: 0.6528 - val_accuracy: 0.7082 - val_loss: 0.7612\nEpoch 32/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 214ms/step - accuracy: 0.7544 - loss: 0.6542 - val_accuracy: 0.7396 - val_loss: 0.6794\nEpoch 33/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 203ms/step - accuracy: 0.7727 - loss: 0.6305 - val_accuracy: 0.7153 - val_loss: 0.7168\nEpoch 34/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 209ms/step - accuracy: 0.7655 - loss: 0.6514 - val_accuracy: 0.7325 - val_loss: 0.6548\nEpoch 35/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 210ms/step - accuracy: 0.7620 - loss: 0.6616 - val_accuracy: 0.6967 - val_loss: 0.8179\nEpoch 36/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 213ms/step - accuracy: 0.7631 - loss: 0.6737 - val_accuracy: 0.7010 - val_loss: 0.8013\nEpoch 37/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 203ms/step - accuracy: 0.7773 - loss: 0.6395 - val_accuracy: 0.7296 - val_loss: 0.7488\nEpoch 38/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 213ms/step - accuracy: 0.7742 - loss: 0.6364 - val_accuracy: 0.7582 - val_loss: 0.6921\nEpoch 39/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 204ms/step - accuracy: 0.7689 - loss: 0.6353 - val_accuracy: 0.7282 - val_loss: 0.7299\nEpoch 40/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 200ms/step - accuracy: 0.7654 - loss: 0.6271 - val_accuracy: 0.7325 - val_loss: 0.6639\nEpoch 41/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 201ms/step - accuracy: 0.7638 - loss: 0.6708 - val_accuracy: 0.7310 - val_loss: 0.7843\nEpoch 42/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 210ms/step - accuracy: 0.7679 - loss: 0.6440 - val_accuracy: 0.7668 - val_loss: 0.6517\nEpoch 43/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 204ms/step - accuracy: 0.7726 - loss: 0.6389 - val_accuracy: 0.7353 - val_loss: 0.6796\nEpoch 44/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 205ms/step - accuracy: 0.7731 - loss: 0.6327 - val_accuracy: 0.7382 - val_loss: 0.7591\nEpoch 45/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 201ms/step - accuracy: 0.7644 - loss: 0.6573 - val_accuracy: 0.7339 - val_loss: 0.6647\nEpoch 46/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 203ms/step - accuracy: 0.7725 - loss: 0.6388 - val_accuracy: 0.7353 - val_loss: 0.6768\nEpoch 47/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 208ms/step - accuracy: 0.7743 - loss: 0.6148 - val_accuracy: 0.7554 - val_loss: 0.6837\nEpoch 48/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 204ms/step - accuracy: 0.7535 - loss: 0.6666 - val_accuracy: 0.7282 - val_loss: 0.6570\nEpoch 49/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 205ms/step - accuracy: 0.7637 - loss: 0.6603 - val_accuracy: 0.7339 - val_loss: 0.7143\nEpoch 50/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 207ms/step - accuracy: 0.7672 - loss: 0.6436 - val_accuracy: 0.7396 - val_loss: 0.7513\nEpoch 51/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 206ms/step - accuracy: 0.7794 - loss: 0.6181 - val_accuracy: 0.7110 - val_loss: 0.7397\nEpoch 52/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 203ms/step - accuracy: 0.7561 - loss: 0.6484 - val_accuracy: 0.7353 - val_loss: 0.6613\nEpoch 53/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 206ms/step - accuracy: 0.7613 - loss: 0.6412 - val_accuracy: 0.7210 - val_loss: 0.7528\nEpoch 54/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 207ms/step - accuracy: 0.7654 - loss: 0.6581 - val_accuracy: 0.7468 - val_loss: 0.6617\nEpoch 55/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 200ms/step - accuracy: 0.7658 - loss: 0.6261 - val_accuracy: 0.7325 - val_loss: 0.6885\nEpoch 56/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 206ms/step - accuracy: 0.7664 - loss: 0.6542 - val_accuracy: 0.7468 - val_loss: 0.6548\nEpoch 57/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 204ms/step - accuracy: 0.7903 - loss: 0.5801 - val_accuracy: 0.7454 - val_loss: 0.6453\nEpoch 58/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 200ms/step - accuracy: 0.7739 - loss: 0.6205 - val_accuracy: 0.7554 - val_loss: 0.7009\nEpoch 59/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 207ms/step - accuracy: 0.7487 - loss: 0.6364 - val_accuracy: 0.7496 - val_loss: 0.6872\nEpoch 60/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 205ms/step - accuracy: 0.7719 - loss: 0.6284 - val_accuracy: 0.7396 - val_loss: 0.6498\nEpoch 61/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 204ms/step - accuracy: 0.7672 - loss: 0.6209 - val_accuracy: 0.7210 - val_loss: 0.7480\nEpoch 62/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 205ms/step - accuracy: 0.7736 - loss: 0.6192 - val_accuracy: 0.7454 - val_loss: 0.6815\nEpoch 63/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 203ms/step - accuracy: 0.7701 - loss: 0.6185 - val_accuracy: 0.7582 - val_loss: 0.6569\nEpoch 64/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 204ms/step - accuracy: 0.7741 - loss: 0.6543 - val_accuracy: 0.7597 - val_loss: 0.6455\nEpoch 65/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 198ms/step - accuracy: 0.7873 - loss: 0.6069 - val_accuracy: 0.7454 - val_loss: 0.6479\nEpoch 66/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 206ms/step - accuracy: 0.7637 - loss: 0.6418 - val_accuracy: 0.7539 - val_loss: 0.7033\nEpoch 67/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 202ms/step - accuracy: 0.7849 - loss: 0.5931 - val_accuracy: 0.7411 - val_loss: 0.6589\nEpoch 68/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 200ms/step - accuracy: 0.7575 - loss: 0.6433 - val_accuracy: 0.7468 - val_loss: 0.6400\nEpoch 69/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 207ms/step - accuracy: 0.7768 - loss: 0.6306 - val_accuracy: 0.7396 - val_loss: 0.6611\nEpoch 70/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 195ms/step - accuracy: 0.7871 - loss: 0.5789 - val_accuracy: 0.7568 - val_loss: 0.6456\nEpoch 71/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 201ms/step - accuracy: 0.7666 - loss: 0.6667 - val_accuracy: 0.7339 - val_loss: 0.7135\nEpoch 72/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 203ms/step - accuracy: 0.7701 - loss: 0.6214 - val_accuracy: 0.7554 - val_loss: 0.6597\nEpoch 73/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 198ms/step - accuracy: 0.7784 - loss: 0.6170 - val_accuracy: 0.7597 - val_loss: 0.6590\nEpoch 74/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 203ms/step - accuracy: 0.7801 - loss: 0.6083 - val_accuracy: 0.7496 - val_loss: 0.6913\nEpoch 75/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 204ms/step - accuracy: 0.7673 - loss: 0.6207 - val_accuracy: 0.7454 - val_loss: 0.6636\n\n========= ğŸ† Fold 2/5 =========\nFound 2794 validated image filenames belonging to 5 classes.\nFound 699 validated image filenames belonging to 5 classes.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/75\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 262ms/step - accuracy: 0.3321 - loss: 1.7565 - val_accuracy: 0.5823 - val_loss: 2.8040\nEpoch 2/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 208ms/step - accuracy: 0.5959 - loss: 1.0789 - val_accuracy: 0.5064 - val_loss: 1.1510\nEpoch 3/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 204ms/step - accuracy: 0.6852 - loss: 0.8945 - val_accuracy: 0.5064 - val_loss: 1.3013\nEpoch 4/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 214ms/step - accuracy: 0.7151 - loss: 0.8392 - val_accuracy: 0.5994 - val_loss: 1.1724\nEpoch 5/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 221ms/step - accuracy: 0.7030 - loss: 0.8047 - val_accuracy: 0.6824 - val_loss: 1.1152\nEpoch 6/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 263ms/step - accuracy: 0.7276 - loss: 0.7836 - val_accuracy: 0.7210 - val_loss: 0.8590\nEpoch 7/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 247ms/step - accuracy: 0.7248 - loss: 0.7885 - val_accuracy: 0.7482 - val_loss: 0.7359\nEpoch 8/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 240ms/step - accuracy: 0.7334 - loss: 0.7361 - val_accuracy: 0.7468 - val_loss: 0.7391\nEpoch 9/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 233ms/step - accuracy: 0.7403 - loss: 0.7517 - val_accuracy: 0.5422 - val_loss: 1.0690\nEpoch 10/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 235ms/step - accuracy: 0.7415 - loss: 0.7122 - val_accuracy: 0.7496 - val_loss: 0.7434\nEpoch 11/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 241ms/step - accuracy: 0.7414 - loss: 0.7300 - val_accuracy: 0.7539 - val_loss: 0.7522\nEpoch 12/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 229ms/step - accuracy: 0.7406 - loss: 0.7370 - val_accuracy: 0.7511 - val_loss: 0.8386\nEpoch 13/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 284ms/step - accuracy: 0.7549 - loss: 0.7047 - val_accuracy: 0.7582 - val_loss: 0.7268\nEpoch 14/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 232ms/step - accuracy: 0.7431 - loss: 0.6929 - val_accuracy: 0.7496 - val_loss: 0.7383\nEpoch 15/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 235ms/step - accuracy: 0.7406 - loss: 0.7015 - val_accuracy: 0.7425 - val_loss: 0.7510\nEpoch 16/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 227ms/step - accuracy: 0.7463 - loss: 0.6952 - val_accuracy: 0.7325 - val_loss: 0.9149\nEpoch 17/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 243ms/step - accuracy: 0.7478 - loss: 0.7003 - val_accuracy: 0.7454 - val_loss: 0.7469\nEpoch 18/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 255ms/step - accuracy: 0.7549 - loss: 0.6727 - val_accuracy: 0.7525 - val_loss: 0.7395\nEpoch 19/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 229ms/step - accuracy: 0.7492 - loss: 0.6983 - val_accuracy: 0.6981 - val_loss: 0.8962\nEpoch 20/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 219ms/step - accuracy: 0.7558 - loss: 0.6717 - val_accuracy: 0.7568 - val_loss: 0.7170\nEpoch 21/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 239ms/step - accuracy: 0.7435 - loss: 0.7060 - val_accuracy: 0.7568 - val_loss: 0.7311\nEpoch 22/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 240ms/step - accuracy: 0.7429 - loss: 0.7088 - val_accuracy: 0.7525 - val_loss: 0.6903\nEpoch 23/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 432ms/step - accuracy: 0.7512 - loss: 0.7069 - val_accuracy: 0.6924 - val_loss: 0.9531\nEpoch 24/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 260ms/step - accuracy: 0.7470 - loss: 0.6818 - val_accuracy: 0.7067 - val_loss: 0.8043\nEpoch 25/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 281ms/step - accuracy: 0.7574 - loss: 0.6592 - val_accuracy: 0.7611 - val_loss: 0.7311\nEpoch 26/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 255ms/step - accuracy: 0.7535 - loss: 0.7050 - val_accuracy: 0.6237 - val_loss: 1.0386\nEpoch 27/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 221ms/step - accuracy: 0.7697 - loss: 0.6460 - val_accuracy: 0.7582 - val_loss: 0.7406\nEpoch 28/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 214ms/step - accuracy: 0.7543 - loss: 0.6841 - val_accuracy: 0.7511 - val_loss: 0.7170\nEpoch 29/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 221ms/step - accuracy: 0.7507 - loss: 0.6657 - val_accuracy: 0.7525 - val_loss: 0.6935\nEpoch 30/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 259ms/step - accuracy: 0.7580 - loss: 0.6476 - val_accuracy: 0.7611 - val_loss: 0.7468\nEpoch 31/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 242ms/step - accuracy: 0.7555 - loss: 0.6597 - val_accuracy: 0.7539 - val_loss: 0.7484\nEpoch 32/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 235ms/step - accuracy: 0.7635 - loss: 0.6409 - val_accuracy: 0.7368 - val_loss: 0.8438\nEpoch 33/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 236ms/step - accuracy: 0.7702 - loss: 0.6612 - val_accuracy: 0.6981 - val_loss: 0.9369\nEpoch 34/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 234ms/step - accuracy: 0.7608 - loss: 0.6881 - val_accuracy: 0.7496 - val_loss: 0.7074\nEpoch 35/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 232ms/step - accuracy: 0.7750 - loss: 0.6451 - val_accuracy: 0.7468 - val_loss: 0.7309\nEpoch 36/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 250ms/step - accuracy: 0.7567 - loss: 0.6621 - val_accuracy: 0.7539 - val_loss: 0.7226\nEpoch 37/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 233ms/step - accuracy: 0.7663 - loss: 0.6373 - val_accuracy: 0.7439 - val_loss: 0.7257\nEpoch 38/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 238ms/step - accuracy: 0.7474 - loss: 0.6687 - val_accuracy: 0.7425 - val_loss: 0.7555\nEpoch 39/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 233ms/step - accuracy: 0.7542 - loss: 0.6759 - val_accuracy: 0.7539 - val_loss: 0.7252\nEpoch 40/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 355ms/step - accuracy: 0.7607 - loss: 0.6554 - val_accuracy: 0.7296 - val_loss: 0.7261\nEpoch 41/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 407ms/step - accuracy: 0.7606 - loss: 0.6241 - val_accuracy: 0.7425 - val_loss: 0.7512\nEpoch 42/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 337ms/step - accuracy: 0.7537 - loss: 0.6677 - val_accuracy: 0.7439 - val_loss: 0.7484\nEpoch 43/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 222ms/step - accuracy: 0.7658 - loss: 0.6755 - val_accuracy: 0.7597 - val_loss: 0.6688\nEpoch 44/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 215ms/step - accuracy: 0.7755 - loss: 0.6191 - val_accuracy: 0.7454 - val_loss: 0.7008\nEpoch 45/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 228ms/step - accuracy: 0.7587 - loss: 0.6595 - val_accuracy: 0.7454 - val_loss: 0.8073\nEpoch 46/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 242ms/step - accuracy: 0.7483 - loss: 0.6608 - val_accuracy: 0.7525 - val_loss: 0.7066\nEpoch 47/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 230ms/step - accuracy: 0.7572 - loss: 0.6558 - val_accuracy: 0.7425 - val_loss: 0.7299\nEpoch 48/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 244ms/step - accuracy: 0.7650 - loss: 0.6268 - val_accuracy: 0.7368 - val_loss: 0.7231\nEpoch 49/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 238ms/step - accuracy: 0.7606 - loss: 0.6279 - val_accuracy: 0.7182 - val_loss: 0.8463\nEpoch 50/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 224ms/step - accuracy: 0.7712 - loss: 0.6178 - val_accuracy: 0.7639 - val_loss: 0.6963\nEpoch 51/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 223ms/step - accuracy: 0.7561 - loss: 0.6421 - val_accuracy: 0.7368 - val_loss: 0.7422\nEpoch 52/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 229ms/step - accuracy: 0.7631 - loss: 0.6243 - val_accuracy: 0.7425 - val_loss: 0.6959\nEpoch 53/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 217ms/step - accuracy: 0.7776 - loss: 0.6208 - val_accuracy: 0.7554 - val_loss: 0.6862\nEpoch 54/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 229ms/step - accuracy: 0.7585 - loss: 0.6282 - val_accuracy: 0.7024 - val_loss: 0.7729\nEpoch 55/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 224ms/step - accuracy: 0.7563 - loss: 0.6539 - val_accuracy: 0.7310 - val_loss: 0.6979\nEpoch 56/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 228ms/step - accuracy: 0.7698 - loss: 0.6169 - val_accuracy: 0.7439 - val_loss: 0.6887\nEpoch 57/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 235ms/step - accuracy: 0.7564 - loss: 0.6381 - val_accuracy: 0.7568 - val_loss: 0.6872\nEpoch 58/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 236ms/step - accuracy: 0.7498 - loss: 0.6497 - val_accuracy: 0.7482 - val_loss: 0.7004\nEpoch 59/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 231ms/step - accuracy: 0.7699 - loss: 0.6057 - val_accuracy: 0.7639 - val_loss: 0.7139\nEpoch 60/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 235ms/step - accuracy: 0.7511 - loss: 0.6359 - val_accuracy: 0.7454 - val_loss: 0.7111\nEpoch 61/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 259ms/step - accuracy: 0.7665 - loss: 0.6118 - val_accuracy: 0.7482 - val_loss: 0.6686\nEpoch 62/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 262ms/step - accuracy: 0.7668 - loss: 0.6245 - val_accuracy: 0.7525 - val_loss: 0.6888\nEpoch 63/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 226ms/step - accuracy: 0.7649 - loss: 0.6312 - val_accuracy: 0.7511 - val_loss: 0.6723\nEpoch 64/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 213ms/step - accuracy: 0.7792 - loss: 0.5896 - val_accuracy: 0.7496 - val_loss: 0.6967\nEpoch 65/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 240ms/step - accuracy: 0.7476 - loss: 0.6612 - val_accuracy: 0.7511 - val_loss: 0.6750\nEpoch 66/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 236ms/step - accuracy: 0.7586 - loss: 0.6349 - val_accuracy: 0.7382 - val_loss: 0.6872\nEpoch 67/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 239ms/step - accuracy: 0.7668 - loss: 0.6131 - val_accuracy: 0.7482 - val_loss: 0.6775\nEpoch 68/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 239ms/step - accuracy: 0.7714 - loss: 0.6116 - val_accuracy: 0.7396 - val_loss: 0.6706\nEpoch 69/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 245ms/step - accuracy: 0.7721 - loss: 0.6197 - val_accuracy: 0.7353 - val_loss: 0.6973\nEpoch 70/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 254ms/step - accuracy: 0.7613 - loss: 0.6373 - val_accuracy: 0.7139 - val_loss: 0.7823\nEpoch 71/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 302ms/step - accuracy: 0.7642 - loss: 0.6168 - val_accuracy: 0.7597 - val_loss: 0.6887\nEpoch 72/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 250ms/step - accuracy: 0.7695 - loss: 0.6186 - val_accuracy: 0.7625 - val_loss: 0.6770\nEpoch 73/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 247ms/step - accuracy: 0.7833 - loss: 0.5924 - val_accuracy: 0.7382 - val_loss: 0.6988\nEpoch 74/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 269ms/step - accuracy: 0.7790 - loss: 0.5889 - val_accuracy: 0.7268 - val_loss: 0.7349\nEpoch 75/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 228ms/step - accuracy: 0.7694 - loss: 0.6034 - val_accuracy: 0.7353 - val_loss: 0.7102\n\n========= ğŸ† Fold 3/5 =========\nFound 2794 validated image filenames belonging to 5 classes.\nFound 699 validated image filenames belonging to 5 classes.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/75\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 517ms/step - accuracy: 0.3962 - loss: 1.5415 - val_accuracy: 0.6452 - val_loss: 1.9022\nEpoch 2/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 522ms/step - accuracy: 0.6261 - loss: 1.0366 - val_accuracy: 0.7096 - val_loss: 0.8232\nEpoch 3/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 253ms/step - accuracy: 0.6903 - loss: 0.8665 - val_accuracy: 0.5336 - val_loss: 1.4858\nEpoch 4/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 218ms/step - accuracy: 0.6789 - loss: 0.8530 - val_accuracy: 0.6152 - val_loss: 0.8326\nEpoch 5/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 250ms/step - accuracy: 0.6754 - loss: 0.8614 - val_accuracy: 0.7382 - val_loss: 0.7927\nEpoch 6/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 256ms/step - accuracy: 0.7144 - loss: 0.8124 - val_accuracy: 0.5336 - val_loss: 1.7312\nEpoch 7/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 267ms/step - accuracy: 0.7241 - loss: 0.7702 - val_accuracy: 0.7396 - val_loss: 0.8537\nEpoch 8/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 262ms/step - accuracy: 0.7176 - loss: 0.7638 - val_accuracy: 0.7525 - val_loss: 0.7431\nEpoch 9/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 265ms/step - accuracy: 0.7228 - loss: 0.7468 - val_accuracy: 0.7582 - val_loss: 0.7563\nEpoch 10/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 257ms/step - accuracy: 0.7264 - loss: 0.7763 - val_accuracy: 0.7053 - val_loss: 1.0865\nEpoch 11/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 245ms/step - accuracy: 0.7397 - loss: 0.7183 - val_accuracy: 0.5336 - val_loss: 1.0441\nEpoch 12/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 229ms/step - accuracy: 0.7416 - loss: 0.7464 - val_accuracy: 0.7496 - val_loss: 0.7428\nEpoch 13/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 218ms/step - accuracy: 0.7477 - loss: 0.7125 - val_accuracy: 0.7597 - val_loss: 0.7623\nEpoch 14/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 214ms/step - accuracy: 0.7327 - loss: 0.7055 - val_accuracy: 0.7182 - val_loss: 0.9280\nEpoch 15/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 233ms/step - accuracy: 0.7296 - loss: 0.7308 - val_accuracy: 0.7325 - val_loss: 0.9216\nEpoch 16/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 233ms/step - accuracy: 0.7399 - loss: 0.7217 - val_accuracy: 0.7582 - val_loss: 0.6996\nEpoch 17/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 232ms/step - accuracy: 0.7267 - loss: 0.7316 - val_accuracy: 0.7439 - val_loss: 0.8289\nEpoch 18/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 242ms/step - accuracy: 0.7572 - loss: 0.6829 - val_accuracy: 0.7654 - val_loss: 0.7220\nEpoch 19/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 221ms/step - accuracy: 0.7387 - loss: 0.6971 - val_accuracy: 0.7210 - val_loss: 0.9188\nEpoch 20/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 231ms/step - accuracy: 0.7508 - loss: 0.6649 - val_accuracy: 0.5336 - val_loss: 1.4028\nEpoch 21/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 330ms/step - accuracy: 0.7494 - loss: 0.7005 - val_accuracy: 0.6209 - val_loss: 1.2523\nEpoch 22/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 353ms/step - accuracy: 0.7500 - loss: 0.6979 - val_accuracy: 0.7654 - val_loss: 0.7075\nEpoch 23/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 251ms/step - accuracy: 0.7417 - loss: 0.6838 - val_accuracy: 0.7353 - val_loss: 0.7633\nEpoch 24/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 243ms/step - accuracy: 0.7452 - loss: 0.6978 - val_accuracy: 0.2833 - val_loss: 4.6915\nEpoch 25/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 291ms/step - accuracy: 0.7449 - loss: 0.7016 - val_accuracy: 0.4306 - val_loss: 2.5472\nEpoch 26/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 268ms/step - accuracy: 0.7340 - loss: 0.7017 - val_accuracy: 0.6466 - val_loss: 1.7581\nEpoch 27/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 273ms/step - accuracy: 0.7389 - loss: 0.7068 - val_accuracy: 0.7539 - val_loss: 0.7183\nEpoch 28/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 265ms/step - accuracy: 0.7653 - loss: 0.6503 - val_accuracy: 0.7597 - val_loss: 0.6627\nEpoch 29/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 276ms/step - accuracy: 0.7428 - loss: 0.7252 - val_accuracy: 0.7639 - val_loss: 0.6692\nEpoch 30/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 280ms/step - accuracy: 0.7461 - loss: 0.6849 - val_accuracy: 0.5336 - val_loss: 1.2013\nEpoch 31/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 279ms/step - accuracy: 0.7482 - loss: 0.6801 - val_accuracy: 0.7682 - val_loss: 0.6416\nEpoch 32/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 235ms/step - accuracy: 0.7407 - loss: 0.6884 - val_accuracy: 0.6595 - val_loss: 1.0244\nEpoch 33/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 215ms/step - accuracy: 0.7516 - loss: 0.6658 - val_accuracy: 0.7425 - val_loss: 0.8686\nEpoch 34/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 232ms/step - accuracy: 0.7642 - loss: 0.6647 - val_accuracy: 0.5336 - val_loss: 1.1893\nEpoch 35/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 228ms/step - accuracy: 0.7447 - loss: 0.6888 - val_accuracy: 0.7153 - val_loss: 1.0150\nEpoch 36/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 261ms/step - accuracy: 0.7533 - loss: 0.6750 - val_accuracy: 0.5336 - val_loss: 1.3904\nEpoch 37/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 220ms/step - accuracy: 0.7607 - loss: 0.6399 - val_accuracy: 0.3090 - val_loss: 4.5978\nEpoch 38/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 265ms/step - accuracy: 0.7527 - loss: 0.6625 - val_accuracy: 0.7296 - val_loss: 0.7865\nEpoch 39/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 218ms/step - accuracy: 0.7605 - loss: 0.6609 - val_accuracy: 0.7268 - val_loss: 1.3189\nEpoch 40/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 227ms/step - accuracy: 0.7372 - loss: 0.6679 - val_accuracy: 0.6252 - val_loss: 0.8933\nEpoch 41/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 280ms/step - accuracy: 0.7590 - loss: 0.6318 - val_accuracy: 0.7740 - val_loss: 0.6480\nEpoch 42/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 269ms/step - accuracy: 0.7416 - loss: 0.6519 - val_accuracy: 0.7668 - val_loss: 0.6862\nEpoch 43/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 237ms/step - accuracy: 0.7470 - loss: 0.6417 - val_accuracy: 0.7639 - val_loss: 0.7024\nEpoch 44/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 226ms/step - accuracy: 0.7606 - loss: 0.6449 - val_accuracy: 0.7568 - val_loss: 0.7220\nEpoch 45/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 258ms/step - accuracy: 0.7497 - loss: 0.6622 - val_accuracy: 0.7768 - val_loss: 0.7133\nEpoch 46/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 209ms/step - accuracy: 0.7537 - loss: 0.6614 - val_accuracy: 0.5336 - val_loss: 1.3027\nEpoch 47/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 213ms/step - accuracy: 0.7511 - loss: 0.6436 - val_accuracy: 0.7339 - val_loss: 0.8084\nEpoch 48/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 209ms/step - accuracy: 0.7556 - loss: 0.6465 - val_accuracy: 0.7139 - val_loss: 0.9167\nEpoch 49/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 207ms/step - accuracy: 0.7557 - loss: 0.6643 - val_accuracy: 0.7740 - val_loss: 0.6534\nEpoch 50/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 233ms/step - accuracy: 0.7654 - loss: 0.6818 - val_accuracy: 0.6781 - val_loss: 0.7936\nEpoch 51/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 264ms/step - accuracy: 0.7490 - loss: 0.6478 - val_accuracy: 0.7768 - val_loss: 0.6925\nEpoch 52/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 207ms/step - accuracy: 0.7569 - loss: 0.6553 - val_accuracy: 0.7353 - val_loss: 0.8219\nEpoch 53/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 209ms/step - accuracy: 0.7508 - loss: 0.6281 - val_accuracy: 0.5894 - val_loss: 0.9810\nEpoch 54/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 225ms/step - accuracy: 0.7637 - loss: 0.6383 - val_accuracy: 0.6495 - val_loss: 0.8692\nEpoch 55/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 228ms/step - accuracy: 0.7639 - loss: 0.6283 - val_accuracy: 0.6381 - val_loss: 0.9135\nEpoch 56/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 239ms/step - accuracy: 0.7536 - loss: 0.6775 - val_accuracy: 0.7783 - val_loss: 0.6393\nEpoch 57/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 237ms/step - accuracy: 0.7501 - loss: 0.6709 - val_accuracy: 0.7854 - val_loss: 0.6282\nEpoch 58/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 226ms/step - accuracy: 0.7551 - loss: 0.6372 - val_accuracy: 0.7225 - val_loss: 0.7223\nEpoch 59/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 230ms/step - accuracy: 0.7742 - loss: 0.6037 - val_accuracy: 0.6767 - val_loss: 0.7664\nEpoch 60/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 214ms/step - accuracy: 0.7618 - loss: 0.6227 - val_accuracy: 0.7296 - val_loss: 0.8688\nEpoch 61/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 259ms/step - accuracy: 0.7701 - loss: 0.6235 - val_accuracy: 0.7811 - val_loss: 0.6164\nEpoch 62/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 207ms/step - accuracy: 0.7630 - loss: 0.6215 - val_accuracy: 0.7496 - val_loss: 0.8244\nEpoch 63/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 205ms/step - accuracy: 0.7492 - loss: 0.6735 - val_accuracy: 0.6080 - val_loss: 0.9066\nEpoch 64/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 201ms/step - accuracy: 0.7526 - loss: 0.6453 - val_accuracy: 0.7682 - val_loss: 0.7947\nEpoch 65/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 207ms/step - accuracy: 0.7361 - loss: 0.6950 - val_accuracy: 0.4106 - val_loss: 1.7533\nEpoch 66/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 201ms/step - accuracy: 0.7430 - loss: 0.6548 - val_accuracy: 0.7597 - val_loss: 0.7029\nEpoch 67/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 207ms/step - accuracy: 0.7602 - loss: 0.6689 - val_accuracy: 0.6810 - val_loss: 0.8007\nEpoch 68/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 211ms/step - accuracy: 0.7537 - loss: 0.6314 - val_accuracy: 0.5551 - val_loss: 1.0186\nEpoch 69/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 204ms/step - accuracy: 0.7533 - loss: 0.6312 - val_accuracy: 0.7482 - val_loss: 0.6709\nEpoch 70/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 203ms/step - accuracy: 0.7736 - loss: 0.5968 - val_accuracy: 0.7611 - val_loss: 0.6426\nEpoch 71/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 202ms/step - accuracy: 0.7556 - loss: 0.6417 - val_accuracy: 0.7096 - val_loss: 0.8029\nEpoch 72/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 203ms/step - accuracy: 0.7684 - loss: 0.6296 - val_accuracy: 0.7454 - val_loss: 0.7397\nEpoch 73/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 207ms/step - accuracy: 0.7605 - loss: 0.6525 - val_accuracy: 0.7368 - val_loss: 0.9204\nEpoch 74/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 205ms/step - accuracy: 0.7532 - loss: 0.6280 - val_accuracy: 0.7039 - val_loss: 0.9089\nEpoch 75/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 213ms/step - accuracy: 0.7720 - loss: 0.6099 - val_accuracy: 0.5551 - val_loss: 1.0240\n\n========= ğŸ† Fold 4/5 =========\nFound 2795 validated image filenames belonging to 5 classes.\nFound 698 validated image filenames belonging to 5 classes.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/75\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 468ms/step - accuracy: 0.2950 - loss: 1.8887 - val_accuracy: 0.6991 - val_loss: 1.2140\nEpoch 2/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 225ms/step - accuracy: 0.6374 - loss: 1.0376 - val_accuracy: 0.6777 - val_loss: 1.0415\nEpoch 3/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 216ms/step - accuracy: 0.6636 - loss: 0.9240 - val_accuracy: 0.7135 - val_loss: 0.8394\nEpoch 4/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 263ms/step - accuracy: 0.7248 - loss: 0.7995 - val_accuracy: 0.7264 - val_loss: 0.8144\nEpoch 5/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 363ms/step - accuracy: 0.6988 - loss: 0.8208 - val_accuracy: 0.7006 - val_loss: 0.8535\nEpoch 6/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 218ms/step - accuracy: 0.7257 - loss: 0.7872 - val_accuracy: 0.5874 - val_loss: 1.0239\nEpoch 7/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 273ms/step - accuracy: 0.7417 - loss: 0.7465 - val_accuracy: 0.7321 - val_loss: 0.8198\nEpoch 8/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 241ms/step - accuracy: 0.7091 - loss: 0.8221 - val_accuracy: 0.6920 - val_loss: 0.8787\nEpoch 9/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 207ms/step - accuracy: 0.7519 - loss: 0.7321 - val_accuracy: 0.7235 - val_loss: 0.7655\nEpoch 10/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 208ms/step - accuracy: 0.7362 - loss: 0.7543 - val_accuracy: 0.7235 - val_loss: 0.7342\nEpoch 11/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 241ms/step - accuracy: 0.7372 - loss: 0.7383 - val_accuracy: 0.7393 - val_loss: 0.7060\nEpoch 12/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 204ms/step - accuracy: 0.7483 - loss: 0.7021 - val_accuracy: 0.7364 - val_loss: 0.7087\nEpoch 13/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 209ms/step - accuracy: 0.7605 - loss: 0.7179 - val_accuracy: 0.7163 - val_loss: 0.7780\nEpoch 14/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 252ms/step - accuracy: 0.7377 - loss: 0.7288 - val_accuracy: 0.7393 - val_loss: 0.7375\nEpoch 15/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 203ms/step - accuracy: 0.7717 - loss: 0.6866 - val_accuracy: 0.7278 - val_loss: 0.7120\nEpoch 16/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 206ms/step - accuracy: 0.7641 - loss: 0.7075 - val_accuracy: 0.6862 - val_loss: 0.8768\nEpoch 17/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 202ms/step - accuracy: 0.7467 - loss: 0.7135 - val_accuracy: 0.7378 - val_loss: 0.7141\nEpoch 18/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 206ms/step - accuracy: 0.7553 - loss: 0.7147 - val_accuracy: 0.7350 - val_loss: 0.7369\nEpoch 19/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 203ms/step - accuracy: 0.7588 - loss: 0.6798 - val_accuracy: 0.7178 - val_loss: 0.7346\nEpoch 20/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 207ms/step - accuracy: 0.7581 - loss: 0.6932 - val_accuracy: 0.6404 - val_loss: 1.0113\nEpoch 21/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 215ms/step - accuracy: 0.7602 - loss: 0.6998 - val_accuracy: 0.7335 - val_loss: 0.7308\nEpoch 22/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 203ms/step - accuracy: 0.7541 - loss: 0.7037 - val_accuracy: 0.7364 - val_loss: 0.7129\nEpoch 23/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 277ms/step - accuracy: 0.7542 - loss: 0.6913 - val_accuracy: 0.7407 - val_loss: 0.7038\nEpoch 24/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 221ms/step - accuracy: 0.7624 - loss: 0.6800 - val_accuracy: 0.7378 - val_loss: 0.7405\nEpoch 25/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 216ms/step - accuracy: 0.7514 - loss: 0.6816 - val_accuracy: 0.7335 - val_loss: 0.7223\nEpoch 26/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 228ms/step - accuracy: 0.7506 - loss: 0.6981 - val_accuracy: 0.7479 - val_loss: 0.7057\nEpoch 27/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 213ms/step - accuracy: 0.7589 - loss: 0.6744 - val_accuracy: 0.7364 - val_loss: 0.7152\nEpoch 28/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 208ms/step - accuracy: 0.7714 - loss: 0.6628 - val_accuracy: 0.7307 - val_loss: 0.7398\nEpoch 29/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 212ms/step - accuracy: 0.7494 - loss: 0.6808 - val_accuracy: 0.6504 - val_loss: 0.8088\nEpoch 30/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 209ms/step - accuracy: 0.7523 - loss: 0.7008 - val_accuracy: 0.6734 - val_loss: 0.7650\nEpoch 31/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 203ms/step - accuracy: 0.7686 - loss: 0.6520 - val_accuracy: 0.7393 - val_loss: 0.7177\nEpoch 32/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 210ms/step - accuracy: 0.7648 - loss: 0.6711 - val_accuracy: 0.7364 - val_loss: 0.7060\nEpoch 33/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 208ms/step - accuracy: 0.7591 - loss: 0.6674 - val_accuracy: 0.6275 - val_loss: 0.9556\nEpoch 34/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 195ms/step - accuracy: 0.7357 - loss: 0.7068 - val_accuracy: 0.7450 - val_loss: 0.7230\nEpoch 35/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 204ms/step - accuracy: 0.7644 - loss: 0.6527 - val_accuracy: 0.6017 - val_loss: 0.9917\nEpoch 36/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 202ms/step - accuracy: 0.7586 - loss: 0.6555 - val_accuracy: 0.7364 - val_loss: 0.7170\nEpoch 37/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 202ms/step - accuracy: 0.7678 - loss: 0.6750 - val_accuracy: 0.7321 - val_loss: 0.7347\nEpoch 38/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 205ms/step - accuracy: 0.7586 - loss: 0.6968 - val_accuracy: 0.7020 - val_loss: 0.7322\nEpoch 39/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 204ms/step - accuracy: 0.7596 - loss: 0.6463 - val_accuracy: 0.7407 - val_loss: 0.7041\nEpoch 40/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 202ms/step - accuracy: 0.7735 - loss: 0.6636 - val_accuracy: 0.7378 - val_loss: 0.7118\nEpoch 41/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 204ms/step - accuracy: 0.7604 - loss: 0.6438 - val_accuracy: 0.7407 - val_loss: 0.7144\nEpoch 42/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 208ms/step - accuracy: 0.7566 - loss: 0.6484 - val_accuracy: 0.7278 - val_loss: 0.7215\nEpoch 43/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 208ms/step - accuracy: 0.7596 - loss: 0.6635 - val_accuracy: 0.7421 - val_loss: 0.7150\nEpoch 44/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 203ms/step - accuracy: 0.7687 - loss: 0.6323 - val_accuracy: 0.7393 - val_loss: 0.7123\nEpoch 45/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 203ms/step - accuracy: 0.7655 - loss: 0.6544 - val_accuracy: 0.6834 - val_loss: 0.7598\nEpoch 46/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 227ms/step - accuracy: 0.7820 - loss: 0.6009 - val_accuracy: 0.7378 - val_loss: 0.6901\nEpoch 47/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 247ms/step - accuracy: 0.7695 - loss: 0.6419 - val_accuracy: 0.7378 - val_loss: 0.7804\nEpoch 48/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 212ms/step - accuracy: 0.7853 - loss: 0.6117 - val_accuracy: 0.7350 - val_loss: 0.6903\nEpoch 49/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 205ms/step - accuracy: 0.7544 - loss: 0.6633 - val_accuracy: 0.4943 - val_loss: 1.2075\nEpoch 50/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 203ms/step - accuracy: 0.7775 - loss: 0.6273 - val_accuracy: 0.7450 - val_loss: 0.7010\nEpoch 51/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 213ms/step - accuracy: 0.7812 - loss: 0.6225 - val_accuracy: 0.7292 - val_loss: 0.7198\nEpoch 52/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 204ms/step - accuracy: 0.7784 - loss: 0.6150 - val_accuracy: 0.7206 - val_loss: 0.7205\nEpoch 53/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 210ms/step - accuracy: 0.7747 - loss: 0.6583 - val_accuracy: 0.7378 - val_loss: 0.7487\nEpoch 54/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 204ms/step - accuracy: 0.7707 - loss: 0.6424 - val_accuracy: 0.7450 - val_loss: 0.6927\nEpoch 55/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 203ms/step - accuracy: 0.7635 - loss: 0.6513 - val_accuracy: 0.7378 - val_loss: 0.7019\nEpoch 56/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 202ms/step - accuracy: 0.7754 - loss: 0.6159 - val_accuracy: 0.7378 - val_loss: 0.7017\nEpoch 57/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 202ms/step - accuracy: 0.7607 - loss: 0.6482 - val_accuracy: 0.7421 - val_loss: 0.7114\nEpoch 58/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 201ms/step - accuracy: 0.7664 - loss: 0.6343 - val_accuracy: 0.7364 - val_loss: 0.6922\nEpoch 59/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 204ms/step - accuracy: 0.7719 - loss: 0.6138 - val_accuracy: 0.7192 - val_loss: 0.7042\nEpoch 60/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 200ms/step - accuracy: 0.7728 - loss: 0.6078 - val_accuracy: 0.7407 - val_loss: 0.6807\nEpoch 61/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 201ms/step - accuracy: 0.7598 - loss: 0.6485 - val_accuracy: 0.7421 - val_loss: 0.6981\nEpoch 62/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 201ms/step - accuracy: 0.7829 - loss: 0.6008 - val_accuracy: 0.7378 - val_loss: 0.7043\nEpoch 63/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 206ms/step - accuracy: 0.7673 - loss: 0.6236 - val_accuracy: 0.7350 - val_loss: 0.6859\nEpoch 64/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 210ms/step - accuracy: 0.7622 - loss: 0.6526 - val_accuracy: 0.7507 - val_loss: 0.6746\nEpoch 65/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 197ms/step - accuracy: 0.7701 - loss: 0.6081 - val_accuracy: 0.7149 - val_loss: 0.7704\nEpoch 66/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 208ms/step - accuracy: 0.7674 - loss: 0.6142 - val_accuracy: 0.7335 - val_loss: 0.7142\nEpoch 67/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 202ms/step - accuracy: 0.7795 - loss: 0.5976 - val_accuracy: 0.7163 - val_loss: 0.7817\nEpoch 68/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 207ms/step - accuracy: 0.7552 - loss: 0.6501 - val_accuracy: 0.7493 - val_loss: 0.6622\nEpoch 69/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 200ms/step - accuracy: 0.7760 - loss: 0.6310 - val_accuracy: 0.7393 - val_loss: 0.6994\nEpoch 70/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 200ms/step - accuracy: 0.7635 - loss: 0.6353 - val_accuracy: 0.7493 - val_loss: 0.6784\nEpoch 71/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 206ms/step - accuracy: 0.7642 - loss: 0.6380 - val_accuracy: 0.7364 - val_loss: 0.6616\nEpoch 72/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 203ms/step - accuracy: 0.7658 - loss: 0.6230 - val_accuracy: 0.7393 - val_loss: 0.6863\nEpoch 73/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 211ms/step - accuracy: 0.7675 - loss: 0.6209 - val_accuracy: 0.7536 - val_loss: 0.6655\nEpoch 74/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 201ms/step - accuracy: 0.7667 - loss: 0.6318 - val_accuracy: 0.7450 - val_loss: 0.6753\nEpoch 75/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 274ms/step - accuracy: 0.7831 - loss: 0.6010 - val_accuracy: 0.7407 - val_loss: 0.6683\n\n========= ğŸ† Fold 5/5 =========\nFound 2795 validated image filenames belonging to 5 classes.\nFound 698 validated image filenames belonging to 5 classes.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/75\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 248ms/step - accuracy: 0.3533 - loss: 1.7491 - val_accuracy: 0.5258 - val_loss: 1.4044\nEpoch 2/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 228ms/step - accuracy: 0.6247 - loss: 1.0464 - val_accuracy: 0.7235 - val_loss: 0.8726\nEpoch 3/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 210ms/step - accuracy: 0.6721 - loss: 0.9087 - val_accuracy: 0.4900 - val_loss: 1.7977\nEpoch 4/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 203ms/step - accuracy: 0.6822 - loss: 0.8695 - val_accuracy: 0.5244 - val_loss: 1.4636\nEpoch 5/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 209ms/step - accuracy: 0.6910 - loss: 0.8641 - val_accuracy: 0.6490 - val_loss: 0.9406\nEpoch 6/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 214ms/step - accuracy: 0.7083 - loss: 0.8432 - val_accuracy: 0.7292 - val_loss: 0.7972\nEpoch 7/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 202ms/step - accuracy: 0.7180 - loss: 0.7925 - val_accuracy: 0.7049 - val_loss: 1.1882\nEpoch 8/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 207ms/step - accuracy: 0.7224 - loss: 0.7911 - val_accuracy: 0.6461 - val_loss: 0.8266\nEpoch 9/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 217ms/step - accuracy: 0.7417 - loss: 0.7776 - val_accuracy: 0.7908 - val_loss: 0.6368\nEpoch 10/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 203ms/step - accuracy: 0.7269 - loss: 0.7865 - val_accuracy: 0.6504 - val_loss: 1.2968\nEpoch 11/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 206ms/step - accuracy: 0.7274 - loss: 0.7864 - val_accuracy: 0.6691 - val_loss: 0.8955\nEpoch 12/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 214ms/step - accuracy: 0.7269 - loss: 0.8038 - val_accuracy: 0.7436 - val_loss: 0.7775\nEpoch 13/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 378ms/step - accuracy: 0.7304 - loss: 0.7556 - val_accuracy: 0.7751 - val_loss: 0.6312\nEpoch 14/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 523ms/step - accuracy: 0.7451 - loss: 0.7216 - val_accuracy: 0.6003 - val_loss: 1.1428\nEpoch 15/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 360ms/step - accuracy: 0.7345 - loss: 0.7456 - val_accuracy: 0.7865 - val_loss: 0.6978\nEpoch 16/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 409ms/step - accuracy: 0.7458 - loss: 0.7368 - val_accuracy: 0.7951 - val_loss: 0.6003\nEpoch 17/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 291ms/step - accuracy: 0.7443 - loss: 0.7317 - val_accuracy: 0.7794 - val_loss: 0.6279\nEpoch 18/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 272ms/step - accuracy: 0.7422 - loss: 0.7293 - val_accuracy: 0.7894 - val_loss: 0.6118\nEpoch 19/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 280ms/step - accuracy: 0.7514 - loss: 0.7216 - val_accuracy: 0.7808 - val_loss: 0.6171\nEpoch 20/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 262ms/step - accuracy: 0.7506 - loss: 0.6952 - val_accuracy: 0.7880 - val_loss: 0.5814\nEpoch 21/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 207ms/step - accuracy: 0.7528 - loss: 0.6977 - val_accuracy: 0.7880 - val_loss: 0.5983\nEpoch 22/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 205ms/step - accuracy: 0.7461 - loss: 0.7364 - val_accuracy: 0.7880 - val_loss: 0.6373\nEpoch 23/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 193ms/step - accuracy: 0.7425 - loss: 0.7094 - val_accuracy: 0.7278 - val_loss: 0.7612\nEpoch 24/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 213ms/step - accuracy: 0.7533 - loss: 0.7143 - val_accuracy: 0.7908 - val_loss: 0.6034\nEpoch 25/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 235ms/step - accuracy: 0.7449 - loss: 0.7035 - val_accuracy: 0.7865 - val_loss: 0.6159\nEpoch 26/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 271ms/step - accuracy: 0.7559 - loss: 0.6924 - val_accuracy: 0.7894 - val_loss: 0.6007\nEpoch 27/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 258ms/step - accuracy: 0.7448 - loss: 0.7045 - val_accuracy: 0.7980 - val_loss: 0.6101\nEpoch 28/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 223ms/step - accuracy: 0.7463 - loss: 0.6832 - val_accuracy: 0.7966 - val_loss: 0.6115\nEpoch 29/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 199ms/step - accuracy: 0.7513 - loss: 0.7136 - val_accuracy: 0.7937 - val_loss: 0.5861\nEpoch 30/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 264ms/step - accuracy: 0.7523 - loss: 0.6899 - val_accuracy: 0.7894 - val_loss: 0.6740\nEpoch 31/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 333ms/step - accuracy: 0.7540 - loss: 0.7011 - val_accuracy: 0.7966 - val_loss: 0.5673\nEpoch 32/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 215ms/step - accuracy: 0.7474 - loss: 0.6998 - val_accuracy: 0.7980 - val_loss: 0.5766\nEpoch 33/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 202ms/step - accuracy: 0.7371 - loss: 0.7110 - val_accuracy: 0.7923 - val_loss: 0.5897\nEpoch 34/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 201ms/step - accuracy: 0.7442 - loss: 0.6929 - val_accuracy: 0.5014 - val_loss: 1.5579\nEpoch 35/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 208ms/step - accuracy: 0.7303 - loss: 0.7112 - val_accuracy: 0.7937 - val_loss: 0.6202\nEpoch 36/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 214ms/step - accuracy: 0.7457 - loss: 0.6826 - val_accuracy: 0.8109 - val_loss: 0.5978\nEpoch 37/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 206ms/step - accuracy: 0.7470 - loss: 0.6912 - val_accuracy: 0.6920 - val_loss: 0.8746\nEpoch 38/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 204ms/step - accuracy: 0.7503 - loss: 0.6866 - val_accuracy: 0.7607 - val_loss: 0.7045\nEpoch 39/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 222ms/step - accuracy: 0.7395 - loss: 0.7144 - val_accuracy: 0.7908 - val_loss: 0.5673\nEpoch 40/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 206ms/step - accuracy: 0.7507 - loss: 0.6858 - val_accuracy: 0.7679 - val_loss: 0.6622\nEpoch 41/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 204ms/step - accuracy: 0.7630 - loss: 0.6532 - val_accuracy: 0.7779 - val_loss: 0.6165\nEpoch 42/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 218ms/step - accuracy: 0.7472 - loss: 0.6733 - val_accuracy: 0.6948 - val_loss: 0.7502\nEpoch 43/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 211ms/step - accuracy: 0.7431 - loss: 0.6654 - val_accuracy: 0.6318 - val_loss: 0.9046\nEpoch 44/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 212ms/step - accuracy: 0.7489 - loss: 0.6709 - val_accuracy: 0.7908 - val_loss: 0.5892\nEpoch 45/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 199ms/step - accuracy: 0.7460 - loss: 0.6727 - val_accuracy: 0.8023 - val_loss: 0.5580\nEpoch 46/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 196ms/step - accuracy: 0.7340 - loss: 0.6890 - val_accuracy: 0.7837 - val_loss: 0.5842\nEpoch 47/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 202ms/step - accuracy: 0.7481 - loss: 0.6831 - val_accuracy: 0.7822 - val_loss: 0.5901\nEpoch 48/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 203ms/step - accuracy: 0.7505 - loss: 0.6490 - val_accuracy: 0.7937 - val_loss: 0.5854\nEpoch 49/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 196ms/step - accuracy: 0.7503 - loss: 0.6801 - val_accuracy: 0.7794 - val_loss: 0.6477\nEpoch 50/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 201ms/step - accuracy: 0.7683 - loss: 0.6281 - val_accuracy: 0.7966 - val_loss: 0.5681\nEpoch 51/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 199ms/step - accuracy: 0.7655 - loss: 0.6233 - val_accuracy: 0.7722 - val_loss: 0.7234\nEpoch 52/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 202ms/step - accuracy: 0.7637 - loss: 0.6638 - val_accuracy: 0.8023 - val_loss: 0.6035\nEpoch 53/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 202ms/step - accuracy: 0.7438 - loss: 0.6810 - val_accuracy: 0.7994 - val_loss: 0.5844\nEpoch 54/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 199ms/step - accuracy: 0.7598 - loss: 0.6479 - val_accuracy: 0.7966 - val_loss: 0.5713\nEpoch 55/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 216ms/step - accuracy: 0.7553 - loss: 0.6771 - val_accuracy: 0.8095 - val_loss: 0.5600\nEpoch 56/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 315ms/step - accuracy: 0.7531 - loss: 0.6734 - val_accuracy: 0.7951 - val_loss: 0.5583\nEpoch 57/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 237ms/step - accuracy: 0.7662 - loss: 0.6356 - val_accuracy: 0.7994 - val_loss: 0.5563\nEpoch 58/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 248ms/step - accuracy: 0.7548 - loss: 0.6587 - val_accuracy: 0.7851 - val_loss: 0.6151\nEpoch 59/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 217ms/step - accuracy: 0.7636 - loss: 0.6543 - val_accuracy: 0.7966 - val_loss: 0.5588\nEpoch 60/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 196ms/step - accuracy: 0.7623 - loss: 0.6397 - val_accuracy: 0.8023 - val_loss: 0.5752\nEpoch 61/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 207ms/step - accuracy: 0.7649 - loss: 0.6580 - val_accuracy: 0.8052 - val_loss: 0.5454\nEpoch 62/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 214ms/step - accuracy: 0.7564 - loss: 0.6622 - val_accuracy: 0.7966 - val_loss: 0.5544\nEpoch 63/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 206ms/step - accuracy: 0.7578 - loss: 0.6336 - val_accuracy: 0.7894 - val_loss: 0.5788\nEpoch 64/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 211ms/step - accuracy: 0.7566 - loss: 0.6343 - val_accuracy: 0.7923 - val_loss: 0.5897\nEpoch 65/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 214ms/step - accuracy: 0.7772 - loss: 0.6146 - val_accuracy: 0.7865 - val_loss: 0.5719\nEpoch 66/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 221ms/step - accuracy: 0.7515 - loss: 0.6649 - val_accuracy: 0.7794 - val_loss: 0.6131\nEpoch 67/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 379ms/step - accuracy: 0.7584 - loss: 0.6430 - val_accuracy: 0.7966 - val_loss: 0.5548\nEpoch 68/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 276ms/step - accuracy: 0.7690 - loss: 0.6375 - val_accuracy: 0.8023 - val_loss: 0.5423\nEpoch 69/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 211ms/step - accuracy: 0.7762 - loss: 0.6331 - val_accuracy: 0.7880 - val_loss: 0.5967\nEpoch 70/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 211ms/step - accuracy: 0.7500 - loss: 0.6564 - val_accuracy: 0.8009 - val_loss: 0.5636\nEpoch 71/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 240ms/step - accuracy: 0.7652 - loss: 0.6280 - val_accuracy: 0.7894 - val_loss: 0.5995\nEpoch 72/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 237ms/step - accuracy: 0.7590 - loss: 0.6521 - val_accuracy: 0.7966 - val_loss: 0.5477\nEpoch 73/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 241ms/step - accuracy: 0.7613 - loss: 0.6335 - val_accuracy: 0.6662 - val_loss: 0.9134\nEpoch 74/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 193ms/step - accuracy: 0.7699 - loss: 0.6198 - val_accuracy: 0.8037 - val_loss: 0.5563\nEpoch 75/75\n\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 202ms/step - accuracy: 0.7612 - loss: 0.6620 - val_accuracy: 0.7980 - val_loss: 0.5606\n\nğŸ“Š Training results saved to: /kaggle/working/CustomVGG16/training_results.csv\nğŸ¯ Best models saved at: /kaggle/working/CustomVGG16\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"/kaggle/working/CustomVGG16.zip","text/html":"<a href='/kaggle/working/CustomVGG16.zip' target='_blank'>/kaggle/working/CustomVGG16.zip</a><br>"},"metadata":{}}],"execution_count":1}]}